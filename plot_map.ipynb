{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Setting\n",
    "Dask is a flexible library for parallel computing in Python. \n",
    "\n",
    "Dask.distributed is a lightweight library for distributed computing in Python.\n",
    "\n",
    "The Client is the primary entry point for users of dask.distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:    tcp://10.32.2.13:39439\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5973dad03e754c468fc402a8f7965ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Distributed computing\n",
    "from dask.distributed import Client, progress\n",
    "from dask_kubernetes import KubeCluster\n",
    "\n",
    "cluster = KubeCluster() # reads provided yaml file\n",
    "# cluster.scale_up(10)  # specify number of nodes explicitly\n",
    "# cluster.adapt(minimum=1, maximum=100)  # or dynamically scale based on current workload\n",
    "cluster.adapt(minimum=1, maximum=25)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-6695ee98-4610-11ea-85ea-da2c4b104ce6\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.32.2.13:39439</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/0000-0001-5234-177x/proxy/8787/status' target='_blank'>/user/0000-0001-5234-177x/proxy/8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.32.2.13:39439' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to distributed cluster and override default\n",
    "client = Client(cluster) \n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setting\n",
    "\n",
    "The pangeo platform is using an old version xesmf. In order to avoid error, we need to update the xesmf by execute the following code:\n",
    "\n",
    "(it seems we need to do it every time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register tcp://10.32.4.3:43291\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.32.4.3:43291\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/JiaweiZhuang/xESMF.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import gcsfs # Pythonic file-system for Google Cloud Storage\n",
    "import xesmf as xe\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, var, model, expe, freq):\n",
    "    try:\n",
    "        uri = df[(df.variable_id == var) & \\\n",
    "                 (df.source_id == model) & \\\n",
    "                 (df.experiment_id == expe) & \\\n",
    "                 (df.table_id == freq)].zstore.values[0]\n",
    "        gcs = gcsfs.GCSFileSystem(token='anon')\n",
    "        ds = xr.open_zarr(gcs.get_mapper(uri), consolidated=True)\n",
    "    except:\n",
    "        ds = []\n",
    "        print(model, \": no data\")\n",
    "    return ds        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the data from 15 models that have biogeochem output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-HR : no data\n",
      "NorCPM1 : no data\n",
      "NorESM2-LM : no data\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/pangeo-cmip6/pangeo-cmip6-zarr-consolidated-stores.csv')\n",
    "models = ['CanESM5', 'CESM2', 'CESM2-WACCM', 'CNRM-ESM2-1', 'GFDL-CM4',\n",
    "          'GFDL-ESM4', 'GISS-E2-1-G', 'GISS-E2-1-G-CC', 'IPSL-CM6A-LR', 'MIROC-ES2L',\n",
    "          'MPI-ESM1-2-HR', 'MRI-ESM2-0', 'NorCPM1', 'NorESM2-LM', 'UKESM1-0-LL']\n",
    "var = 'tos'\n",
    "expe = 'historical'\n",
    "freq = 'Omon'\n",
    "\n",
    "start_time = '1991'\n",
    "end_time = '2010'\n",
    "\n",
    "xrays = []\n",
    "for model in models:\n",
    "    xray = get_data(df, var, model, expe, freq)\n",
    "    xrays.append(xray)\n",
    "xray_dic = {key:value for key, value in zip(models, xrays)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aves = []\n",
    "\n",
    "for model in tqdm(models):\n",
    "    try:\n",
    "        ds = xray_dic[model].sel(time=slice('1990','2009')).mean(dim='time').tos\n",
    "        \n",
    "        if 'latitude' in ds.coords:\n",
    "            ds = ds.rename({'longitude': 'lon', 'latitude': 'lat'})\n",
    "        if 'nav_lat' in ds.coords:\n",
    "            ds = ds.rename({'nav_lon': 'lon', 'nav_lat': 'lat'})\n",
    "            \n",
    "        ds = ds.load()\n",
    "        outname = 'mean/' + str(model) + '.nc'\n",
    "        ds.to_netcdf(outname)\n",
    "            \n",
    "    except Exception as E:\n",
    "        ds = []\n",
    "        print(model, E)\n",
    "\n",
    "    aves.append(ds)\n",
    "\n",
    "ave_dic = {key:value for key, value in zip(models, aves)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regridding\n",
    "\n",
    "Behzad's code for regridding:\n",
    "\n",
    "nearest from scipy.interpolate.datagrid\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.griddata.html\n",
    "\n",
    "Here we use xesmf\n",
    "https://xesmf.readthedocs.io/en/latest/notebooks/Compare_algorithms.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (x: 360, x_b: 361, y: 180, y_b: 181)\n",
       "Coordinates:\n",
       "    lon      (y, x) float64 -179.5 -178.5 -177.5 -176.5 ... 177.5 178.5 179.5\n",
       "    lat      (y, x) float64 -89.5 -89.5 -89.5 -89.5 ... 89.5 89.5 89.5 89.5\n",
       "    lon_b    (y_b, x_b) int64 -180 -179 -178 -177 -176 ... 176 177 178 179 180\n",
       "    lat_b    (y_b, x_b) int64 -90 -90 -90 -90 -90 -90 -90 ... 90 90 90 90 90 90\n",
       "Dimensions without coordinates: x, x_b, y, y_b\n",
       "Data variables:\n",
       "    *empty*</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (x: 360, x_b: 361, y: 180, y_b: 181)\n",
       "Coordinates:\n",
       "    lon      (y, x) float64 -179.5 -178.5 -177.5 -176.5 ... 177.5 178.5 179.5\n",
       "    lat      (y, x) float64 -89.5 -89.5 -89.5 -89.5 ... 89.5 89.5 89.5 89.5\n",
       "    lon_b    (y_b, x_b) int64 -180 -179 -178 -177 -176 ... 176 177 178 179 180\n",
       "    lat_b    (y_b, x_b) int64 -90 -90 -90 -90 -90 -90 -90 ... 90 90 90 90 90 90\n",
       "Dimensions without coordinates: x, x_b, y, y_b\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Global 2D rectilinear grid of 1 degree x 1 degree\n",
    "ds_out = xe.util.grid_global(1, 1)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (lat: 181, lon: 361)\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 -90.0 -89.0 -88.0 -87.0 -86.0 ... 87.0 88.0 89.0 90.0\n",
       "  * lon      (lon) float64 0.0 1.0 2.0 3.0 4.0 ... 356.0 357.0 358.0 359.0 360.0\n",
       "Data variables:\n",
       "    *empty*</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 181, lon: 361)\n",
       "Coordinates:\n",
       "  * lat      (lat) float64 -90.0 -89.0 -88.0 -87.0 -86.0 ... 87.0 88.0 89.0 90.0\n",
       "  * lon      (lon) float64 0.0 1.0 2.0 3.0 4.0 ... 356.0 357.0 358.0 359.0 360.0\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another method for out grid:\n",
    "ds_out = xr.Dataset({'lat': (['lat'], np.arange(-90, 91, 1.0)),\n",
    "                     'lon': (['lon'], np.arange(0, 361, 1.0)),\n",
    "                    }\n",
    "                   )\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrids = []\n",
    "for model in tqdm(models):\n",
    "    try:\n",
    "        dsf = 'mean/' + str(model) + '.nc'\n",
    "        ds = xr.open_dataset(dsf)\n",
    "        \n",
    "        dsr = xe.Regridder(ds, ds_out, 'bilinear', periodic=True, ignore_degenerate=True)\n",
    "        dsr_out = dsr(ds)\n",
    "        dsr.clean_weight_file()\n",
    "        \n",
    "        #outname = 'Regrid/' + str(model) + '_reg.nc'\n",
    "        #dsr_out.to_netcdf(outname)\n",
    "        \n",
    "    except Exception as E:\n",
    "        dsr_out = []\n",
    "        print(model, E)\n",
    "    regrids.append(dsr_out)\n",
    "regrid_dic = {key:value for key, value in zip(models, regrids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create weight file: bilinear_291x360_181x361_peri.nc\n",
      "Remove file bilinear_291x360_181x361_peri.nc\n",
      "Create weight file: bilinear_384x320_181x361_peri.nc\n",
      "Remove file bilinear_384x320_181x361_peri.nc\n",
      "Create weight file: bilinear_180x360_181x361_peri.nc\n",
      "Remove file bilinear_180x360_181x361_peri.nc\n",
      "Create weight file: bilinear_294x362_181x361_peri.nc\n",
      "Remove file bilinear_294x362_181x361_peri.nc\n",
      "Create weight file: bilinear_1080x1440_181x361_peri.nc\n",
      "Remove file bilinear_1080x1440_181x361_peri.nc\n",
      "Create weight file: bilinear_576x720_181x361_peri.nc\n",
      "Remove file bilinear_576x720_181x361_peri.nc\n",
      "Create weight file: bilinear_90x144_181x361_peri.nc\n",
      "Remove file bilinear_90x144_181x361_peri.nc\n",
      "Create weight file: bilinear_90x144_181x361_peri.nc\n",
      "Remove file bilinear_90x144_181x361_peri.nc\n",
      "Create weight file: bilinear_332x362_181x361_peri.nc\n",
      "Remove file bilinear_332x362_181x361_peri.nc\n",
      "Create weight file: bilinear_256x360_181x361_peri.nc\n",
      "Remove file bilinear_256x360_181x361_peri.nc\n",
      "Create weight file: bilinear_363x360_181x361_peri.nc\n",
      "Remove file bilinear_363x360_181x361_peri.nc\n",
      "Create weight file: bilinear_330x360_181x361_peri.nc\n",
      "Remove file bilinear_330x360_181x361_peri.nc\n",
      "CPU times: user 2min 32s, sys: 21 s, total: 2min 53s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regrids = []\n",
    "for model in models:\n",
    "    if isinstance(xray_dic[model], xr.Dataset):\n",
    "        ds = xray_dic[model].sel(time=slice(start_time, end_time))[var]\n",
    "        \n",
    "        if 'latitude' in ds.coords:\n",
    "            ds = ds.rename({'longitude': 'lon', 'latitude': 'lat'})\n",
    "        if 'nav_lat' in ds.coords:\n",
    "            ds = ds.rename({'nav_lon': 'lon', 'nav_lat': 'lat'})\n",
    "            \n",
    "                \n",
    "        dsr = xe.Regridder(ds, ds_out, 'bilinear', periodic=True, ignore_degenerate=True)\n",
    "        dsr._grid_in = None\n",
    "        dsr._grid_out = None\n",
    "        dsr_out = dsr(ds)\n",
    "        dsr.clean_weight_file()\n",
    "        \n",
    "    else:\n",
    "        dsr_out = []\n",
    "        \n",
    "    regrids.append(dsr_out)\n",
    "    \n",
    "regrid_dic = {key:value for key, value in zip(models, regrids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Retire worker names (0,)\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [0]\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.32.4.3:43291\n",
      "distributed.core - INFO - Removing comms to tcp://10.32.4.3:43291\n",
      "distributed.scheduler - INFO - Lost all workers\n",
      "distributed.scheduler - INFO - Retire worker names (1,)\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [1]\n",
      "distributed.scheduler - INFO - Retire worker names (2, 3)\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [2, 3]\n",
      "distributed.scheduler - INFO - Register tcp://10.32.4.4:37409\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.32.4.4:37409\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Retire worker names (4,)\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [4]\n",
      "distributed.scheduler - INFO - Retire worker names (5,)\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [5]\n",
      "distributed.scheduler - INFO - Retire worker names (6,)\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [6]\n",
      "distributed.scheduler - INFO - Remove worker tcp://10.32.4.4:37409\n",
      "distributed.core - INFO - Removing comms to tcp://10.32.4.4:37409\n",
      "distributed.scheduler - INFO - Lost all workers\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "i = 0\n",
    "for model in models:  \n",
    "    i = i + 1\n",
    "    if isinstance(xray_dic[model], list):\n",
    "        continue\n",
    "    else:\n",
    "        s = regrid_dic[model].mean(dim='time')\n",
    "    ax = plt.subplot(5,3,i)\n",
    "    plt.pcolormesh(regrid_dic[model].lon, regrid_dic[model].lat, s, cmap=plt.cm.RdBu_r)\n",
    "    plt.colorbar()\n",
    "    ax.title.set_text(str(model))\n",
    "plt.tight_layout()\n",
    "plt.savefig('tos.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove client Client-84e0f60a-460c-11ea-85ea-ceae867a2ccd\n",
      "distributed.scheduler - INFO - Remove client Client-84e0f60a-460c-11ea-85ea-ceae867a2ccd\n",
      "distributed.scheduler - INFO - Close client connection: Client-84e0f60a-460c-11ea-85ea-ceae867a2ccd\n",
      "distributed.scheduler - INFO - Scheduler closing...\n",
      "distributed.scheduler - INFO - Scheduler closing all comms\n"
     ]
    }
   ],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
